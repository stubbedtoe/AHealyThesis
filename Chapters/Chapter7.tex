\chapter{Conclusion}
\thispagestyle{nohead}
\label{Conclusion}

This thesis has presented a strategy to choose appropriate SMT solvers based on the syntactic features of \why~POs.
%Through the use of \where, We find that \where~can out-perform individual solvers by proving a greater number of goals in a shorter average time. 
Our final solution, \where, was implemented after a careful consideration of a number of datasets (Sec. \ref{sub:lrsvmm}), SMT-solving tools (Sec. \ref{sec:selection}), learning tasks (Sec \ref{sec:reg-class}) and learning algorithms (Sec. \ref{pred:choosing}).

The \where~tool is a random-forest multi-output regressor with a number of optimisation heuristics.
Users without any knowledge of SMT solvers (i.e. those choosing solvers at random) can prove a greater number of goals in less time by delegating to \where. 
Although the prediction accuracy of \where~is disappointing on some instances of the test set, we maintain that \where~represents a positive first step in developing the portfolio solver that would simplify discharging POs for non-expert \why~users.


We believe that the \why~platform has great potential for machine-learning based portfolio-solving due to its unique approach to interfacing with disparate ATP, SMT and ITP tools.
We are encouraged by the performance of a theoretical \textsf{Best Ranking} strategy.
The convenience that such a tool would give \why~users has the potential to make deductive software verification more approachable to the wider software engineering community and provides a motivation for improving \where~through future work.

\section{Future Work}
\label{sec:future}

The number of potential directions for this work is large.
An obvious and immediate first step could be the use of a larger and more generic dataset for training and testing purposes.
The two viable alternatives to the \why~example dataset discussed in Sec. \ref{sub:why3programs} -- the TPTP library \cite{TPTP} and the BWARE dataset \cite{Delahaye2014} -- could be investigated to this end.
 
The application of an initial splitting transformation (to simplify each PO) would also be relatively simple to implement.
This would also create an entirely different, and potentially much larger, dataset. 
For example, applying the \texttt{split\_goal\_wp} transform to each PO in the \why~example dataset would increase its size from 1048 to 7489 POs.
Of course, any changes to the dataset would require repeating the costly measurement of dependant variables (Sec. \ref{sec:dependant}).

An interesting direction for this work could be the identification of the simplifying transformations (both splitting and non-splitting) which would need to be applied by \why~in order for a PO to be tractable for an SMT solver.
The tool resulting from this multi-class classification task would be quite different to the one implemented as \where~-- but  potentially very useful.
It would complement the existing \where~tool in its goal to assist non-expert \why~users in discharging proof obligations through automation.

Applying multiple solvers in parallel could potentially alleviate some of the time penalties associated with \where~and portfolio solvers in general (identified in Sec. \ref{sec:eq1}).
The effectiveness of such an approach has been demonstrated by the \texttt{ppfolio} (Parallel PortFOLIO) SAT tool which won 11 medals at the SAT 2011 competition \cite{Malitsky2012}.
All SMT solvers could either be scheduled to run in parallel (thereby eliminating the need for feature extraction and prediction) or alternatively only the solvers with the lowest predicted cost could be run.
There is a trade-off in the allocation of computational resources associated with these two approaches are: the time and CPU cycles needed for feature extraction and solver prediction must be balanced with those consumed by a number of low-performing solvers.     
 
As mentioned in Sec. \ref{sec:eq3} in response to Evaluation Question 3, future work could investigate the re-implementation of \where~as a \why~plugin in order to optimise the interaction with \why's internal data structures used for feature extraction.
Aside from the implementation of the \where~tool itself, a
\textit{minimal benchmark suite} could be identified which could be used to train the prediction model using new SMT solvers and theorem provers installed locally.
%Such a suite could build on previous work \cite{Healy:2016} which used clustering to   
